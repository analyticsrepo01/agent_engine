{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview) is a managed service that helps you to build and deploy agent frameworks. [LangGraph](https://langchain-ai.github.io/langgraph/) is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.\n",
    "\n",
    "This notebook demonstrates how to build, deploy, and test a simple LangGraph application using [Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview) in Vertex AI. You'll learn how to combine LangGraph's workflow orchestration with the scalability of Vertex AI, which enables you to build custom generative AI applications.\n",
    "\n",
    "Note that the approach used in this notebook defines a [custom application template in Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/customize), which can be extended to LangChain or other orchestration frameworks. If just want to use Agent Engine to build agentic generative AI applications, refer to the documentation for [developing with the LangChain template in Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/develop/overview).\n",
    "\n",
    "This notebook covers the following steps:\n",
    "\n",
    "- **Define Tools**: Create custom Python functions to act as tools your AI application can use.\n",
    "- **Define Router**: Set up routing logic to control conversation flow and tool selection.\n",
    "- **Build a LangGraph Application**: Structure your application using LangGraph, including the Gemini model and custom tools that you define.\n",
    "- **Local Testing**: Test your LangGraph application locally to ensure functionality.\n",
    "- **Deploying to Vertex AI**: Seamlessly deploy your LangGraph application to Agent Engine for scalable execution.\n",
    "- **Remote Testing**: Interact with your deployed application through Vertex AI, testing its functionality in a production-like environment.\n",
    "- **Cleaning Up Resources**: Delete your deployed application on Vertex AI to avoid incurring unnecessary charges.\n",
    "\n",
    "By the end of this notebook, you'll have the skills and knowledge to build and deploy your own custom generative AI applications using LangGraph, Agent Engine, and Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tFy3H3aPgx12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aider-chat 0.84.0 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\n",
      "aider-chat 0.84.0 requires google-auth==2.40.1, but you have google-auth 2.40.3 which is incompatible.\n",
      "aider-chat 0.84.0 requires openai==1.75.0, but you have openai 1.86.0 which is incompatible.\n",
      "aider-chat 0.84.0 requires pydantic==2.11.4, but you have pydantic 2.11.2 which is incompatible.\n",
      "aider-chat 0.84.0 requires pydantic-core==2.33.2, but you have pydantic-core 2.33.1 which is incompatible.\n",
      "aider-chat 0.84.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
      "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.1 which is incompatible.\n",
      "crewai 0.121.0 requires litellm==1.68.0, but you have litellm 1.68.1 which is incompatible.\n",
      "embedchain 0.1.128 requires posthog<4.0.0,>=3.0.2, but you have posthog 4.0.1 which is incompatible.\n",
      "embedchain 0.1.128 requires rich<14.0.0,>=13.7.0, but you have rich 14.0.0 which is incompatible.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\n",
      "instructor 1.8.3 requires jiter<0.9,>=0.6.1, but you have jiter 0.9.0 which is incompatible.\n",
      "instructor 1.8.3 requires rich<14.0.0,>=13.7.0, but you have rich 14.0.0 which is incompatible.\n",
      "litellm 1.68.1 requires openai<1.76.0,>=1.68.2, but you have openai 1.86.0 which is incompatible.\n",
      "vertexai 1.71.1 requires google-cloud-aiplatform[all]==1.71.1, but you have google-cloud-aiplatform 1.98.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --user --quiet \\\n",
    "    \"google-cloud-aiplatform[agent_engines,langchain]\" \\\n",
    "    cloudpickle==3.0.0 \\\n",
    "    \"pydantic==2.11.2\" \\\n",
    "    langgraph \\\n",
    "    httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "STAGING_BUCKET = \"gs://veretxai_image_recognition_02\"  # @param {type:\"string\"}\n",
    "\n",
    "PROJECT_ID=\"my-project-0004-346516\"\n",
    "\n",
    "if not PROJECT_ID:\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdvJRUWRNGHE"
   },
   "source": [
    "## Building and deploying a LangGraph app on Agent Engine\n",
    "\n",
    "In the following sections, we'll walk through the process of building and deploying a LangGraph application using Agent Engine in Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b3004f33544"
   },
   "source": [
    "### Import libraries\n",
    "\n",
    "Import the necessary Python libraries. These libraries provide the tools we need to interact with LangGraph, Vertex AI, and other components of our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "67acfba81563"
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from vertexai import agent_engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94db54ba756b"
   },
   "source": [
    "### Define tools\n",
    "\n",
    "You'll start by defining the a tool for your LangGraph application. You'll define a custom Python function that act as tools in our agentic application.\n",
    "\n",
    "In this case, we'll define a simple tool that returns a product description based on the product that the user asks about. In reality, you can write functions to call APIs, query databases, or anything other tasks that you might want your agent to be able to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "22981b2e1c59"
   },
   "outputs": [],
   "source": [
    "def get_product_details(product_name: str):\n",
    "    \"\"\"Gathers basic details about a product.\"\"\"\n",
    "    details = {\n",
    "        \"smartphone\": \"A cutting-edge smartphone with advanced camera features and lightning-fast processing.\",\n",
    "        \"coffee\": \"A rich, aromatic blend of ethically sourced coffee beans.\",\n",
    "        \"shoes\": \"High-performance running shoes designed for comfort, support, and speed.\",\n",
    "        \"headphones\": \"Wireless headphones with advanced noise cancellation technology for immersive audio.\",\n",
    "        \"speaker\": \"A voice-controlled smart speaker that plays music, sets alarms, and controls smart home devices.\",\n",
    "    }\n",
    "    return details.get(product_name, \"Product details not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be70714d9fae"
   },
   "source": [
    "### Define router\n",
    "\n",
    "Then, you'll define a router to control the flow of the conversation, determining which tool to use based on user input or the state of the interaction. Here we'll use a simple router setup, and you can customize the behavior of your router to handle multiple tools, custom logic, or multi-agent workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "516b5108d327"
   },
   "outputs": [],
   "source": [
    "def router(state: list[BaseMessage]) -> Literal[\"get_product_details\", \"__end__\"]:\n",
    "    \"\"\"Initiates product details retrieval if the user asks for a product.\"\"\"\n",
    "    # Get the tool_calls from the last message in the conversation history.\n",
    "    tool_calls = state[-1].tool_calls\n",
    "    # If there are any tool_calls\n",
    "    if len(tool_calls):\n",
    "        # Return the name of the tool to be called\n",
    "        return \"get_product_details\"\n",
    "    else:\n",
    "        # End the conversation flow.\n",
    "        return \"__end__\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d32ce189d989"
   },
   "source": [
    "### Define LangGraph application\n",
    "\n",
    "Now you'll bring everything together to define your LangGraph application as a custom template in Agent Engine.\n",
    "\n",
    "This application will use the tool and router that you just defined. LangGraph provides a powerful way to structure these interactions and leverage the capabilities of LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6eeff14856cd"
   },
   "outputs": [],
   "source": [
    "class SimpleLangGraphApp:\n",
    "    def __init__(self, project: str, location: str) -> None:\n",
    "        self.project_id = project\n",
    "        self.location = location\n",
    "\n",
    "    # The set_up method is used to define application initialization logic\n",
    "    def set_up(self) -> None:\n",
    "        model = ChatVertexAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "        builder = MessageGraph()\n",
    "\n",
    "        model_with_tools = model.bind_tools([get_product_details])\n",
    "        builder.add_node(\"tools\", model_with_tools)\n",
    "\n",
    "        tool_node = ToolNode([get_product_details])\n",
    "        builder.add_node(\"get_product_details\", tool_node)\n",
    "        builder.add_edge(\"get_product_details\", END)\n",
    "\n",
    "        builder.set_entry_point(\"tools\")\n",
    "        builder.add_conditional_edges(\"tools\", router)\n",
    "\n",
    "        self.runnable = builder.compile()\n",
    "\n",
    "    # The query method will be used to send inputs to the agent\n",
    "    def query(self, message: str):\n",
    "        \"\"\"Query the application.\n",
    "\n",
    "        Args:\n",
    "            message: The user message.\n",
    "\n",
    "        Returns:\n",
    "            str: The LLM response.\n",
    "        \"\"\"\n",
    "        chat_history = self.runnable.invoke(HumanMessage(message))\n",
    "\n",
    "        return chat_history[-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be06c89a87aa"
   },
   "source": [
    "### Local testing\n",
    "\n",
    "In this section, you'll test your LangGraph app locally before deploying it to ensure that it behaves as expected before deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6e2cb6d16e34"
   },
   "outputs": [],
   "source": [
    "agent = SimpleLangGraphApp(project=PROJECT_ID, location=LOCATION)\n",
    "agent.set_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fc70cda0aeb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'High-performance running shoes designed for comfort, support, and speed.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query(message=\"Get product details for shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9550ed5f509d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A rich, aromatic blend of ethically sourced coffee beans.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query(message=\"Get product details for coffee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3675a218d107"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A cutting-edge smartphone with advanced camera features and lightning-fast processing.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query(message=\"Get product details for smartphone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "72351589a51b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, I cannot provide weather information. I can only provide details about products.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask a question that cannot be answered using the defined tools\n",
    "agent.query(message=\"Tell me about the weather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ccd4227e8c8"
   },
   "source": [
    "### Deploy your LangGraph app\n",
    "\n",
    "Now that you verified that your LangGraph application is working locally, it's time to deploy it to Agent Engine! This will make your application accessible remotely and allow you to integrate it into larger systems or provide it as a service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dced52d8c524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified the following requirements: {'pydantic': '2.11.2', 'cloudpickle': '3.0.0'}\n",
      "The final list of requirements: ['google-cloud-aiplatform[agent_engines,langchain]', 'cloudpickle==3.0.0', 'pydantic==2.11.2', 'langgraph', 'httpx']\n",
      "Using bucket veretxai_image_recognition_02\n",
      "Wrote to gs://veretxai_image_recognition_02/agent_engine/agent_engine.pkl\n",
      "Writing to gs://veretxai_image_recognition_02/agent_engine/requirements.txt\n",
      "Creating in-memory tarfile of extra_packages\n",
      "Writing to gs://veretxai_image_recognition_02/agent_engine/dependencies.tar.gz\n",
      "Creating AgentEngine\n",
      "Create AgentEngine backing LRO: projects/255766800726/locations/us-central1/reasoningEngines/7257383673740132352/operations/1459027569004249088\n",
      "View progress and logs at https://console.cloud.google.com/logs/query?project=my-project-0004-346516\n",
      "AgentEngine created. Resource name: projects/255766800726/locations/us-central1/reasoningEngines/7257383673740132352\n",
      "To use this AgentEngine in another session:\n",
      "agent_engine = vertexai.agent_engines.get('projects/255766800726/locations/us-central1/reasoningEngines/7257383673740132352')\n"
     ]
    }
   ],
   "source": [
    "remote_agent = agent_engines.create(\n",
    "    SimpleLangGraphApp(project=PROJECT_ID, location=LOCATION),\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform[agent_engines,langchain]\",\n",
    "        \"cloudpickle==3.0.0\",\n",
    "        \"pydantic==2.11.2\",\n",
    "        \"langgraph\",\n",
    "        \"httpx\",\n",
    "    ],\n",
    "    display_name=\"Agent Engine with LangGraph\",\n",
    "    description=\"This is a sample custom application in Agent Engine that uses LangGraph\",\n",
    "    extra_packages=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b876ca670960"
   },
   "source": [
    "### Remote test\n",
    "\n",
    "Now that your LangGraph app is running on Agent Engine, let's test it out by querying it in the remote environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8836a18a41f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'High-performance running shoes designed for comfort, support, and speed.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_agent.query(message=\"Get product details for shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "374c15e64016"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A rich, aromatic blend of ethically sourced coffee beans.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_agent.query(message=\"Get product details for coffee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5952d817da5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A cutting-edge smartphone with advanced camera features and lightning-fast processing.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_agent.query(message=\"Get product details for smartphone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8b425533042c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, I cannot provide weather information. I can only gather basic details about a product. What product are you interested in?\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_agent.query(message=\"Tell me about the weather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a4e033321ad"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "After you've finished experimenting, it's a good practice to clean up your cloud resources. You can delete the deployed Agent Engine instance to avoid any unexpected charges on your Google Cloud account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eb5fbfa43866",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete Agent Engine backing LRO: projects/255766800726/locations/us-central1/operations/4607254814768758784\n",
      "Agent Engine deleted. Resource name: projects/255766800726/locations/us-central1/reasoningEngines/7257383673740132352\n"
     ]
    }
   ],
   "source": [
    "# remote_agent.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "tutorial_langgraph.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
